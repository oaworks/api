<!DOCTYPE html>
<html dir="ltr" lang="en">

<head>
  <meta charset="utf-8">

  <title>OA.Works API</title>
  <meta name="description" content="">
  <meta name="author" content="Mark MacGillivray">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <link href="//fonts.googleapis.com/css?family=Lustria|Noto+Sans|Roboto+Slab|Nixie+One" rel="stylesheet" type="text/css">
  <script type="text/javascript" src="/client/oaworksLogin.min.js"></script>

  <style>
    html { height: 100%; }
    html, body {
      margin: 0;
      padding: 0;
    }
    body {
      min-height: 100%;
      background: #FFFFFC;
      color: #5F5C64;
      font-size: 1em;
      font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }

    .nav {
      background: #24201e;
      height: 50px;
      top: 0;
      position: -webkit-sticky;
      position: sticky;
      z-index: 1101;
    }
    .page {
      max-width: 800px;
      margin: 0 auto 200px auto;
    }
    #panel {
      position: fixed;
      top: 0;
      left: 0;
      bottom: 0;
      min-width: 23%;
      border-right: 2px solid #ccc;
      padding: 90px 5px 5px 10px;
      background: #eee; 
      z-index: 1000;
    }
    @media (max-width: 1000px) { #panel { width: 99%; } }
    #panel + .page { margin: 0 auto 200px 33%; }
    @media (max-width: 1200px) { #panel + .page { margin: 0 auto 200px 29%; } }
    @media (max-width: 1130px) { #panel + .page { margin: 0 auto 200px auto; } }

    code, pre { 
      font-family: Menlo, Monaco, Consolas, "Courier New", monospace; 
    }
    code {
      padding: 2px 4px;
      font-size: 90%;
      color: #c7254e;
      white-space: nowrap;
      background: #f9f2f4;
      border-radius: 0.2em;
    }
    pre {
      background: #333;
      color: white;
      margin-bottom: 0 0 35px 10px;
      display: block;
      padding: 9.5px;
      font-size: 13px;
      line-height: 1.428571429;
      word-break: break-all;
      word-wrap: break-word;
      border: 1px solid #ccc;
      border-radius: 0.2em;
    }
    pre code {
      padding: 0;
      font-size: inherit;
      color: inherit;
      white-space: pre-wrap;
      background-color: transparent;
      border-radius: 0;
    }

    a {
      color: #428bca;
      text-decoration: none;
    }
    a:hover { text-decoration: underline; }
    a:focus { outline: thin dotted; }
    
    h1, h2, h3, h4, h5, h6 {
      word-wrap: break-word;
      font-family: 'Roboto Slab', 'Noto Sans', Arial, Verdana, sans-serif;
      margin-top: 40px;
      margin-bottom: 5px;
    }
    h3 {
      line-height: 1.6em;
      font-size: 1.4em;
    }
    h4 {
      line-height: 1.6em;
      font-size: 1.3em;
    }
    h5 {
      line-height: 1.6em;
      font-size: 1.2em;
    }
    h6 {
      line-height: 1.6em;
      font-size: 1.1em;
    }
    
    p {
      margin: 0px 0px 18px 2px;
      text-align: justify;
      line-height: 1.6em;
      letter-spacing: 0.1em;
      word-wrap: break-word;
    }
    
    ul {
      margin-bottom: 30px;
      margin-left: -40px;
      list-style-type: none;
    }
    ul li {
      margin-top: 5px;
      line-height: 1.3em;
      letter-spacing: 0.1em;
      word-wrap: break-word;
    }

    hr {
      margin: 40px 0px 40px 0px;
    }
  </style>
</head>

<body>

<div class="nav">
  <p style="line-height:0.9em;padding-top:10px;"><a style="color:#FFFFFC;" href="/docs">&nbsp;&nbsp;OA.<br>&nbsp;&nbsp;&nbsp;Works docs</a></p>
</div>

<div id="panel">
  <div class="contents"></div>
</div>

<div class="page">

<a name="quickstart"></a>
<h1 style="text-align:center;">OA.Works API framework</h1>

<hr></hr>
<p>The OA.Works API is minimalist node.js providing things like auth, caching, workers, search, and more.</p>

<pre>
<code class="request curl">curl <a target="_blank" href="/">https://api.oa.works</a>
</code><code style="display:none;" class="request node"># you may first need to install node-fetch using npm or your preferred package manager
import fetch from 'node-fetch'
res = await fetch('https://api.oa.works')
console.log(res)
</code><code style="display:none;" class="request python"># you may first need to install requests using pip or your preferred package manager
import requests
res = requests.get('https://api.oa.works')
print(res.json())
</code>
<a class="requesting" href="node">Node</a> | <a class="requesting" href="python">Python</a>
</pre>



<h2>Using OA.Works API</h2>

<p>We run the API four ourselves and for you to try out. Please limit your requests to 
two per second and include an email address in a <b>User-Agent</b> header 
(or <a class="goto" href="#auth">sign up and use an API key</a>) in case we need to contact you.</p>

<p>The <a target="_blank" href="/status">/status</a> page lists available routes.
Some routes may only be visible or accessible with authorisation, so use your 
API key (or email and resume key) on your requests.</p>

<pre>
<code>curl -X GET '<a target="_blank" href="https://api.oa.works">https://api.oa.works</a>' -H 'User-Agent: youremail@yourdomain.com'
curl '<a target="_blank" href="https://api.oa.works/status">https://api.oa.works/status</a>' -H 'x-apikey: ...'
curl '<a target="_blank" href="https://api.oa.works/status">https://api.oa.works/status?apikey=...</a>'</code>
</pre>



<h3 name="auth">Auth</h3>

<p><b>/auth</b> routes handle user and group management. We use passwordless login, and 
all that is necessary to start an account is to provide a valid email address - you will 
receive a login token to type back into the login page, and then you're logged in. Repeat 
the process any time you need to get logged in again.</p>

<p>To login directly via the API, start by requesting an auth token to be sent to your email 
address; once it arrives, send it back to the <b>/auth</b> endpoint:</p>

<pre>
<code>curl 'https://api.oa.works/auth/token?email=...'
curl 'https://api.oa.works/auth?token=...'</code>
</pre>

<p>That's it, you're logged in, and can include <b>email</b> and <b>resume</b> 
parameters to subsequent requests - you'll find the <b>resume</b> value in the response object. 
You can logout by sending an authorised GET request to <a href="/auth/logout">/auth/logout</a>.</p>

<p>Custom signup/login pages should be made when developing your own service.
When a user signs in using the browser UI your code should set a cookie so 
further browser-based requests won't require another login. Subsequent UI 
requests should then be coded to send the cookie, or read the email and resume 
keys and send them as parameters.</p>


<h4>Roles</h4>

<p>Some endpoints will require you to have a particular <b>role</b> as well as being logged in. 
If you're logged in and still refused access, the refusal response object may include a URL 
or email address to send a request to be assigned the role.</p>


<h3>Sources</h3>

<p><b>/src</b> routes are used to connect to some remote source. As our main 
project goals over the years have been about academic research, most of these are for querying 
and caching useful remote datasets. For example we have a <b>/src</b> route to query and cache the 
<a target="_blank" href="https://www.crossref.org/documentation/retrieve-metadata/rest-api/">Crossref API</a>.</p>

<p>The point of these routes is to make it really easy to integrate with other 
services. Instead of having to remember how to use some other API, or write a separate library 
to use them, one endpoint can be added to encapsulate that knowledge.</p>

<p>Go directly to the main route of a <b>/src</b> to find more information about it.</p>

<pre>
<code>curl <a target="_blank" href="/src/crossref">https://api.oa.works/src/crossref</a></code>
</pre>

<p>(These parts of documentation are still in progress - sorry if you don't find anything 
useful; looking at the code of a src and the notes surrounding it will have to suffice for now.)</p>



<h4>Search</h4>

<p>One of the most powerful features is easy integration with an Elasticsearch 
index for storing, searching, and analysing data. A data endpoint can be created with just 
one setting, which enables search and also automatically configures some additional endpoints:</p>

<pre>
<code>curl '<a target="_blank" href='/src/crossref/works?q="public%20library%20of%20science"'>/src/crossref/works?q="public%20library%20of%20science"</a>'
curl '<a target="_blank" href="/src/crossref/works/keys">/src/crossref/works/keys</a>'
curl '<a target="_blank" href="/src/crossref/works/terms">/src/crossref/works/terms</a>'
curl '<a target="_blank" href="/src/crossref/works/suggest">/src/crossref/works/suggest</a>'
curl '<a target="_blank" href="/src/crossref/works/count">/src/crossref/works/count</a>'
curl '<a target="_blank" href="/src/crossref/works/min">/src/crossref/works/min</a>'
curl '<a target="_blank" href="/src/crossref/works/max">/src/crossref/works/max</a>'
curl '<a target="_blank" href="/src/crossref/works/range">/src/crossref/works/range</a>'</code>
</pre>

<p>The full documentation for Elasticsearch queries is very good, so we recommend
<a target="_blank" href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/query-dsl.html">
checking out their docs directly</a>.</p>



<hr></hr>

<h2 name="deployment">Deployment</h2>

<p>How and why to run a bg server (the demo already is one)</p>

<pre>
<code class="install linux">sudo apt install nodejs
git clone <a target="_blank" href="https://github.com/oaworks/API">https://github.com/oaworks/API.git</a>
cd API
npm install coffeescript uglify-js uglifycss
coffee construct.coffee
node server/dist/server.min.js
</code><code style="display:none;" class="install apple"># you'll need homebrew installed
# https://brew.sh
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
brew update
brew install git
brew install nodejs
git clone https://github.com/oaworks/API.git
cd API
npm install coffeescript uglify-js uglifycss
coffee construct.coffee
node server/dist/server.min.js
</code><code style="display:none;" class="install windows"># Not too sure about this one... we don't use Windows!.
# install git for windows: https://gitforwindows.org
# install node.js and npm for windows...
# use npm to install coffeescript uglify-js uglifycss
# clone the repo: https://github.com/oaworks/API.git
# in the "API" directory, run "coffee construct.coffee"
# then run "node server/dist/server.min.js"
</code>
<a class="installing" href="apple">Apple</a> | <a class="installing" href="windows">Windows</a>
</pre>
<!-- | <a class="goto" href="#development">Development docs</a> -->

<p>We use Cloudflare Workers however we don't want to be tied
to one provider, so the API can run anywhere that node.js can run. 
Where we use particular Cloudflare infrastructure such as Workers KV, we also consider our 
fallback position such as writing to Elasticsearch if KV is not available, and planning that 
later we could easily update our key/value store code to use Redis instead.</p>


<h3>Cloudflare worker</h3>

<p>To deploy your own cloudflare worker, first 
<a href="https://workers.cloudflare.com">sign up or login</a> to cloudflare. 
Everything you need for the demo and even to run a pretty powerful API is available 
in the free tier. Once signed up, copy your account ID and API token from the cloudflare dashboard main page. 
You'll find it displayed near the bottom right.</p>

<p>Next, <a class="goto" href="#install">clone our git repo</a> (if you haven't already) and create a folder 
called <b>secrets</b> in the main API folder, and in there create a file called 
<b>construct.json</b>.</p>

<pre>
<code>cd API
mkdir secrets && touch secrets/construct.json
vim secrets/construct.json</code>
</pre>

<p>In that file, write a JSON object with the keys <b>ACCOUNT_ID</b>, <b>API_TOKEN</b>, 
and <b>SCRIPT_ID</b>. Use the values you copied from cloudflare for the first two, and the 
script ID can be whatever you want to call your worker. Once you've saved your construct file, 
run the constructor!</p>

<pre>
<code>coffee construct.coffee</code>
</pre>

<p>Cloudflare provide a great tool called 
<a target="_blank" href="https://developers.cloudflare.com/workers/cli-wrangler">wrangler</a> 
which can be used to deploy and configure your worker. We don't use wrangler because we want to remain 
independent of any one platform, but if you don't have such concerns, it may be worth 
looking into.</p>

<p>Now you should have your own API up and running in a cloudflare worker! Note it won't 
be able to save anything yet though. So, continue on to read about Settings & 
Secrets, and Elasticsearch.</p>


<h3 name="settings">Settings & secrets</h3>

<p>The standard demo makes a few assumptions about the environment, and limits what 
can be done with it. The major limitation is that it does not know 
where Elasticsearch is so it can't save any data - so you'll want to configure some 
settings.</p>

<p>We differentiate between settings and secrets. Settings are anything that you want 
to be able to easily configure, and perhaps have different values for development vs 
production versions, where as secrets are settings like API keys for other services - 
you wouldn't want to share them in your repo or in a web browser.</p>

<p>We have the git repo configured to ignore any file in any folder called <b>secrets</b> 
anywhere in the repo. Create a <b>secrets</b> folder in the <b>worker</b> and <b>server</b> 
folders as well, and in those you can put settings/secrets relevant to each. So you can write 
any settings or secrets in the <b>secrets</b> folders you create. 
But you can also put settings in any file in the code, or create new files and put settings 
in them. We have one in our worker code called <b>settings.json</b>, for example, and it can 
be seen in the repo because it's not inside a secrets folder (and we don't put secrets in it).</p>

<p>There's also a hierarchy to the secrets and settings. At the top level there's 
the main secrets folder where you would have created your <b>construct</b> file - 
it's secret because your cloudflare API keys are in there. 
Nothing from that file gets included in the main code, it's only used by the constructor 
for deployments. Note, you can also provide a list of objects in that file if you want 
to deploy identical workers to different cloudflare accounts.</p>

<p>Anything set in the worker folder will be 
available in the worker and also in the server, if you do run and build your own server, 
because the server runs a local copy of the worker.</p>

<p>Any setting in the server folder will only be available if you run your own server, 
they won't be copied into a worker deployed to cloudflare.</p>

<p>The most useful secrets to put in your first settings file will be the ones that 
enable your API to save data so your API can save data - so read on about setting 
up Elasticsearch.</p>


<h3>Elasticsearch</h3>

<p>We use Elasticsearch 7.10.0, and we use the Amazon Open Distro version. You can 
use any version you like, as long as it's new enough to be compatible with 7.x index 
structures. We run our own cluster on <a href="https://digitalocean.com">Digital Ocean</a>, 
but you can use any provider you prefer, or even run it locally on your own machine to 
try out.</p>

<p>There are providers who will run Elasticsearch for you. We've found them 
all to be pretty expensive for production scaling, so it's cheaper for us to run our own. 
If you're just getting started and aren't comfortable with sysadmin, 
<a target="_blank" href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&all-free-tier.q=elasticsearch&all-free-tier.q_operator=AND">
Amazon Web Services provide a small free tier</a> that is probably the easiest way to 
run a cluster, and you can just 
<a target="_blank" href="https://aws.amazon.com/elasticsearch-service/pricing/">pay to scale it up</a>
later if you want.</p>

<p>Once you sign up and start an Elasticsearch service, you'll get a URL to your own cluster, and probably a 
<b>username:password</b> combination. Put those in your <b>worker/secrets/settings.json</b> like so:</p>

<pre>
<code>{
  "index": {
    "url": "https://username:password@your.index.com" # A URL to your elasticsearch
  }
}</code>
</pre>

<p>Installing Elasticsearch to try out is pretty easy on Linux, we're not sure about Apple 
or Windows though - their documentation does explain how, but we've never tried it. Managing 
a large production cluster can get complicated, but it does give you more power and control 
in comparison to paying a service provider for it. Also, whilst Elasticsearch itself is free 
and open source, and you can run it on your own laptop to start with, you'll need to pay for 
a machine or cluster of machines to run it in production, so keep that in mind.</p>

<p>Rather than us writing more instructions that will get out of date, it's best to go straight to the source - 
check out the 
<a target="_blank" href="https://www.elastic.co/elastic-stack">Elasticsearch</a> or
<a target="_blank" href="https://opendistro.github.io/for-elasticsearch-docs/docs/install">Open Distro</a>
docs.</p>



<h3>Code structure</h3>

<p>Code is split into <b>worker</b> and <b>server</b>. Worker is where the vast bulk of code is, and where 
any future code would most likely go. Server is only for code that can only run on a background server. Everything 
in worker gets compiled into the server code as well. It's possible to write worker code that also only runs in a 
background context as there is a _bg wrapper option too. So what would go in server? A good example is what we have 
in our <b>src</b> endpoints, where in the server folder we have defined functions that bulk load millions of records 
into an index - there would never be any advantage running this in a worker context, so we write it straight into 
the server folder instead.</p>

<p>Worker code is deployed as a Cloudflare worker, although this is optional - it is also possible to deploy the server 
bundle anywhere that any Node.js app can be run, and to run clusters for scalability. So you could run your own copy 
anywhere you like.</p>

<p>The code itself is in the <b>src</b> directories found in worker and server. Both have an <b>api.coffee</b> file 
that is their main controller - the worker one handles integration with Cloudflare workers environment, whereas 
the server one runs the code as a typical Node.js server app available on localhost.</p>

<p>When the top level <b>construct.coffee</b> is run, it generates minified js worker and server files in their 
respective <b>dist</b> folders - these should not be edited directly. The worker dist file is then deployed to 
Cloudflare (if configured) and the server dist file can be used to run locally.</p>

<p>Every function of the API is defined as a value on the global object <b>P</b>. Whenever the worker API 
controller runs (which is also called by the server API controller) it provides a new instance of P to process 
the incoming request. So any function declared on P automatically becomes an API endpoint, available at a URL named 
after the dot notation key of the function.</p>



<h3>Wrapper config</h3>

<p><b>_auth</b> - if true an authorised user is required. If a string or a list, an authorised user with that role
(or one of the listed roles) is required. An empty list can be used to indicate that a user with a role 
equivalent to the route or a subset of the route is required.</p>

<p><b>_cache</b> - defaults to ... Otherwise can be set to false or a number indicating how many seconds the cache is 
valid for. (Passing refresh param on an incoming request wil override a cache.)</p>

<p>Note _auth and _cache are ALWAYS and ONLY checked first at the incoming request level.</p>

<p><b>_kv</b> - if true store the result in the key/value store, and check for it on new requests. Cloudflare KV is global with 1s eventual consistency - whereas Cloudflare cache is regional.</p>
<p><b>_index</b> - if true send the result to an index. It can be an object of index initialisation settings, mappings, aliases.</p>
<p><b>_key</b> - optionally specify which key name in a result object to lookup for a suitable ID value for the result.</p>
<p><b>_sheet</b> - if true get a sheet ID from settings for the given route. Or it can directly be the sheet ID string. If present it implies _index:true.</p>

<p><b>_async</b> - if true, don't wait for the result, just return _async:@rid. Subsequent requests can provide the @rid in a param called _async to check progress.</p>

<p><b>_bg</b> - if true run the function on the background server. Note this can happen at the top level request route or if that route calls any _bg function.</p>

<p><b>_hide</b> - if true a function will not show up on the list of available routes - but it <b>IS</b> still accessible.
(If necessary a function can be written on the API object and yet be hidden AND inaccessible via a route, by prefixing the 
function name with an underscore.)</p>



</body>

<script>
var toc = '<div class="P_contents" style="font-size:0.9em; overflow-y:auto; height:100%;"><ul>';
var counter = 0;
_OALogin('h2,h3', function(el) {
  counter++;
  header = _OALogin.html(el);
  _OALogin.prepend(el, '<a name="toc' + counter + '"></a>');
  toc += '<li>';
  var spaces = 0;
  var ms = 2 * (parseInt(el.nodeName.toLowerCase().replace('h','')) - 2);
  while (spaces < ms) {
    toc += '&nbsp;'
    spaces++;
  }
  toc += '<a class="goto" href="#toc' + counter + '">' + header + '</a></li>';
});
_OALogin.html('.contents', toc + '</ul></div>');

_OALogin.on('click', '.goto', function(e) {
  e.preventDefault();
  window.scrollTo(0, P(_OALogin.attr(e.target, 'href').replace('#', '')).offsetTop - 70);
});

_OALogin.on('click', '.installing', function(e) {
  e.preventDefault();
  _OALogin.hide('.install');
  _OALogin.show('.' + _OALogin.attr(e.target, 'href'));
});
_OALogin.on('click', '.requesting', function(e) {
  e.preventDefault();
  _OALogin.hide('.request');
  _OALogin.show('.' + _OALogin.attr(e.target, 'href'));
});
</script>

</html>
