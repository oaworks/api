<!DOCTYPE html>
<html dir="ltr" lang="en">

<head>
  <meta charset="utf-8">

  <title>OA.Works API</title>
  <meta name="description" content="">
  <meta name="author" content="Mark MacGillivray">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <link href="//fonts.googleapis.com/css?family=Lustria|Noto+Sans|Roboto+Slab|Nixie+One" rel="stylesheet" type="text/css">

  <style>
    html { height: 100%; }
    html, body {
      margin: 0;
      padding: 0;
    }
    body {
      min-height: 100%;
      background: #FFFFFC;
      color: #5F5C64;
      font-size: 1em;
      font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }

    .nav {
      background: #24201e;
      height: 50px;
      top: 0;
      position: -webkit-sticky;
      position: sticky;
      z-index: 1101;
    }
    .page {
      max-width: 800px;
      margin: 0 auto 200px auto;
    }
    #panel {
      position: fixed;
      top: 0;
      left: 0;
      bottom: 0;
      min-width: 23%;
      border-right: 2px solid #ccc;
      padding: 90px 5px 5px 10px;
      background: #eee; 
      z-index: 1000;
    }
    @media (max-width: 1000px) { #panel { min-width: 0px; width: 0px; padding: 0px; } }
    #panel + .page { margin: 0 auto 200px 33%; }
    @media (max-width: 1200px) { #panel + .page { margin: 0 auto 200px 29%; } }
    @media (max-width: 1130px) { #panel + .page { margin: 0 auto 200px auto; } }

    code, pre { 
      font-family: Menlo, Monaco, Consolas, "Courier New", monospace; 
    }
    code {
      padding: 2px 4px;
      font-size: 90%;
      color: #c7254e;
      white-space: nowrap;
      background: #f9f2f4;
      border-radius: 0.2em;
    }
    pre {
      background: #333;
      color: white;
      margin-bottom: 0 0 35px 10px;
      display: block;
      padding: 9.5px;
      font-size: 13px;
      line-height: 1.428571429;
      word-break: break-all;
      word-wrap: break-word;
      border: 1px solid #ccc;
      border-radius: 0.2em;
    }
    pre code {
      padding: 0;
      font-size: inherit;
      color: inherit;
      white-space: pre-wrap;
      background-color: transparent;
      border-radius: 0;
    }

    a {
      color: #428bca;
      text-decoration: none;
    }
    a:hover { text-decoration: underline; }
    a:focus { outline: thin dotted; }
    
    h1, h2, h3, h4, h5, h6 {
      word-wrap: break-word;
      font-family: 'Roboto Slab', 'Noto Sans', Arial, Verdana, sans-serif;
      margin-top: 40px;
      margin-bottom: 5px;
    }
    h3 {
      line-height: 1.6em;
      font-size: 1.4em;
    }
    h4 {
      line-height: 1.6em;
      font-size: 1.3em;
    }
    h5 {
      line-height: 1.6em;
      font-size: 1.2em;
    }
    h6 {
      line-height: 1.6em;
      font-size: 1.1em;
    }
    
    p {
      margin: 0px 0px 18px 2px;
      text-align: justify;
      line-height: 1.6em;
      letter-spacing: 0.1em;
      word-wrap: break-word;
    }
    
    ul {
      margin-bottom: 30px;
      margin-left: -40px;
      list-style-type: none;
    }
    ul li {
      margin-top: 5px;
      line-height: 1.3em;
      letter-spacing: 0.1em;
      word-wrap: break-word;
    }

    hr {
      margin: 40px 0px 40px 0px;
    }
  </style>
</head>

<body>

<div class="nav">
  <p style="line-height:0.9em;padding-top:10px;"><a style="color:#FFFFFC;" href="/docs">&nbsp;&nbsp;OA.<br>&nbsp;&nbsp;&nbsp;Works docs</a></p>
</div>

<div id="panel">
  <div class="contents"></div>
</div>

<div class="page">

<a name="quickstart"></a>
<h1 style="text-align:center;">OA.Works API</h1>

<hr></hr>

<pre>
<code class="request curl">curl <a target="_blank" href="/">https://api.oa.works</a>
</code><code style="display:none;" class="request node"># you may first need to install node-fetch using npm or your preferred package manager
import fetch from 'node-fetch'
res = await fetch('https://api.oa.works')
console.log(res)
</code><code style="display:none;" class="request python"># you may first need to install requests using pip or your preferred package manager
import requests
res = requests.get('https://api.oa.works')
print(res.json())
</code>
<a class="requesting" href="node">Node</a> | <a class="requesting" href="python">Python</a>
</pre>



<h2>Using OA.Works API</h2>

<p>Please limit requests to 
two per second and include an email address in a <b>User-Agent</b> header 
(or <a href="#auth">sign up and use an API key</a>) in case we need to contact you.
Or contact us to discuss higher rate limits.</p>

<p>The <a target="_blank" href="/status">/status</a> page lists available routes.
Some routes may only be visible or accessible with authorisation, so use your 
API key (or email and resume key) on your requests.</p>

<pre>
<code>curl -X GET '<a target="_blank" href="https://api.oa.works">https://api.oa.works/status</a>' -H 'User-Agent: youremail@yourdomain.com'
curl '<a target="_blank" href="https://api.oa.works/status">https://api.oa.works/status</a>' -H 'x-apikey: ...'
curl '<a target="_blank" href="https://api.oa.works/status">https://api.oa.works/status?apikey=...</a>'</code>
</pre>



<h2 name="auth">Auth</h2>

<p><b>/auth</b> routes handle user and group management. We use a passwordless 
approach. To login directly via the API, start by requesting an auth token to 
be sent to your email address; once it arrives, send it back to the <b>/auth</b> endpoint:</p>

<pre>
<code>curl 'https://api.oa.works/auth/token?email=...'
curl 'https://api.oa.works/auth?token=...'</code>
</pre>

<p>That's it, you're logged in. Include your <b>email</b> and <b>resume</b> 
parameters to subsequent requests - you'll find the <b>resume</b> value in the 
response of your token submission. You can logout by sending an authorised GET 
request to <a href="/auth/logout">/auth/logout</a>.</p>

<p>It's also possible to login on a web browser. Go to 
<a href="/auth">/auth</a>, put in your email address, then once you receive 
your token you can type it into that page as well. Once you're logged in a cookie 
will be set in the browser for you, so subsequent requests are automatically authorised.</p>

<p>Some endpoints will require you to have a particular <b>role</b> as well as being logged in. 
If you're logged in and still refused access, the refusal response object may include a URL 
or email address to send a request to be assigned the role. Some roles may also 
be scoped to the domain of your email address.</p>


<h2>Sources</h2>

<p><b>/src</b> routes are used to connect to some remote source. As our main 
project goals over the years have been about academic research, most of these are for querying 
and caching useful remote datasets. For example we have a <b>/src</b> route to query and cache the 
<a target="_blank" href="https://www.crossref.org/documentation/retrieve-metadata/rest-api/">Crossref API</a>.</p>

<p>The point of these routes is to make it really easy to integrate with other 
services. Instead of having to remember how to use some other API, or write a separate library 
to use them, one endpoint can be added to encapsulate that knowledge.</p>

<p>Go directly to the main route of a <b>/src</b> to find more information about it.</p>

<pre>
<code>curl <a target="_blank" href="/src/crossref">https://api.oa.works/src/crossref</a></code>
</pre>




<h4>Search</h4>

<p>OA.Works integrates with Elasticsearch. A data endpoint can be created with just 
one setting, which enables search:</p>

<pre>
<code>curl '<a target="_blank" href='/src/crossref/works?q="public%20library%20of%20science"'>/src/crossref/works?q="public%20library%20of%20science"</a>'</code>
</pre>

<p>It also automatically configures some additional 
endpoints:</p>

<pre>
<code>curl '<a target="_blank" href="/src/crossref/works/keys">/src/crossref/works/keys</a>'
curl '<a target="_blank" href="/src/crossref/works/terms">/src/crossref/works/terms</a>'
curl '<a target="_blank" href="/src/crossref/works/suggest">/src/crossref/works/suggest</a>'
curl '<a target="_blank" href="/src/crossref/works/count">/src/crossref/works/count</a>'
curl '<a target="_blank" href="/src/crossref/works/min">/src/crossref/works/min</a>'
curl '<a target="_blank" href="/src/crossref/works/max">/src/crossref/works/max</a>'
curl '<a target="_blank" href="/src/crossref/works/range">/src/crossref/works/range</a>'
curl '<a target="_blank" href="/src/crossref/works/range">/src/crossref/works/mapping</a>'</code>
</pre>

<p>The full documentation for Elasticsearch is very good, so we recommend
<a target="_blank" href="https://www.elastic.co/guide/en/elasticsearch/reference/7.10/query-dsl.html">
checking out their docs directly</a> instead of us replicating it here.</p>



<hr></hr>

<h2 name="deployment">Installation / Deployment</h2>

<p>This requires a background server and / or Cloudflare Workers. Workers give a 
very robust API distributed across the whole Cloudflare network, whereas a 
background server allows for long-running and maintenance tasks (and if you're 
running your own Elasticsearch, you've got a machine to run it on anyway).</p>

<h2>Background server</h2>

<p>Although Cloudflare Workers are great, it's not great to be tied
to one provider, so the API can run anywhere that node.js can run.</p>

<pre>
<code class="install linux">sudo apt install nodejs
git clone <a target="_blank" href="https://github.com/oaworks/API">https://github.com/oaworks/API.git</a>
cd API
npm install coffeescript uglify-js uglifycss
coffee construct.coffee
node server/dist/server.min.js
</code><code style="display:none;" class="install apple"># you'll need homebrew installed
# https://brew.sh
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
brew update
brew install git
brew install nodejs
git clone https://github.com/oaworks/API.git
cd API
npm install coffeescript uglify-js uglifycss
coffee construct.coffee
node server/dist/server.min.js
</code><code style="display:none;" class="install windows"># Not too sure about this one... we don't use Windows!.
# install git for windows: https://gitforwindows.org
# install node.js and npm for windows...
# use npm to install coffeescript uglify-js uglifycss
# clone the repo: https://github.com/oaworks/API.git
# in the "API" directory, run "coffee construct.coffee"
# then run "node server/dist/server.min.js"
</code>
<a class="installing" href="apple">Apple</a> | <a class="installing" href="windows">Windows</a>
</pre>


<h2>Cloudflare worker</h2>

<p>To deploy a worker,
<a href="https://workers.cloudflare.com">sign up or login</a> to Cloudflare and 
note your account ID and API token from the bottom right of the dashboard main page.</p>

<p>Next, <a target="_blank" href="https://github.com/oaworks/API">clone our git repo</a> and create a folder 
called <b>secrets</b> in the main API folder, and in there create a file called 
<b>construct.json</b>.</p>

<pre>
<code>cd API
mkdir secrets && touch secrets/construct.json
vim secrets/construct.json</code>
</pre>

<p>In that file, write a JSON object with the keys <b>ACCOUNT_ID</b>, <b>API_TOKEN</b>, 
and <b>SCRIPT_ID</b>. Use the values you copied from cloudflare for the first two, and the 
script ID can be whatever you want to call your worker. Then run the constructor.</p>

<pre>
<code>coffee construct.coffee</code>
</pre>

<p>Cloudflare provides a deployment tool called 
<a target="_blank" href="https://developers.cloudflare.com/workers/cli-wrangler">wrangler</a> 
which can be used to deploy and configure your worker. We don't use wrangler because we want to remain 
independent of any one platform, but if you don't have such concerns, it may be worth 
looking into.</p>

<p>Now you should have your own API up and running in a cloudflare worker.
However the default deployment has to make a few assumptions, and limits what 
can be done with it. The major limitation is that it does not know 
where Elasticsearch is so it can't save any data. To fix this, you need to 
configure some <b>settings</b> and <b>secrets</b>.</p>


<h2 name="settings">Structure, Settings, Secrets</h2>

<p>Code is split in two - <b>worker</b> is where the bulk of code is, and it's where
functionality should go by default. It must all be able to run on a Cloudflare worker. 
<b>Server</b> is only for code that can only run on a background server. Everything 
in worker gets compiled into the server code as well, so it doesn't need duplicated.</p>

<p>The code itself is in the <b>src</b> directories found in each of <b>worker</b> 
and <b>server</b>. <b>api.coffee</b> is the main file. 
The worker one handles integration with Cloudflare workers environment, whereas 
the server one runs the code as a typical Node.js server app available on localhost. 
When the top level <b>construct.coffee</b> is run, it generates minified js worker 
and server files in their respective <b>dist</b> folders - these should not be 
edited directly. The construct script then deploys the worker dist file to 
Cloudflare if suitable settings are available to allow it, and the server dist file 
can be used to run locally.</p>

<p>Every function of the API is defined as a value on the global object <b>P</b>. 
Whenever the worker API controller runs (which is also called by the server API 
controller) it provides a new instance of P to process the incoming request. So 
any function declared on P automatically becomes an API endpoint, available at a 
URL named after the dot notation key of the function. There is a function wrapper 
and configuration pattern, similiar to python decorators - more detail about this 
would be useful for future development but is not necessary for sysadmin.</p>

<p><b>Settings</b> are anything that you want 
to be able to easily configure, and perhaps have different values for development vs 
production versions - but they don't necessarily need to be secret. Settings can 
go in any file in the code, or create new files and put settings in them. For example 
you can simply manage them all in a file called settings.json.</p>

<p><b>Secrets</b> are just special settings, they're things like API keys for other services - 
you wouldn't want to share them in your repo or in a web browser, they need to be kept secret.
Git is configured to ignore any file in any folder called <b>secrets</b>. 
Create a <b>secrets</b> folder in the <b>worker</b> and <b>server</b> 
folders, and in those you can put settings/secrets relevant to each.</p>

<p>Any setting in the server folder will only be available if you run your own server, 
they won't be sent to Cloudflare for use by a worker. Any setting in the worker folder will be 
sent to cloudflare for use by the worker, and also copied into the server dist.</p>

<p>The most useful secrets to put in your first settings file will be the ones that 
enable your API to connect to Elasticsearch so you can index data.</p>


<h2>Elasticsearch</h2>

<p>We use the Amazon Open Distro version of Elasticsearch 7.10.0. </p>

<p>There are providers who will run Elasticsearch for you however long term it's cheaper to 
run your own if you know how. 
<a target="_blank" href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&all-free-tier.q=elasticsearch&all-free-tier.q_operator=AND">
Amazon Web Services provide a small free tier</a> that is probably the easiest way to 
get started, and you can 
<a target="_blank" href="https://aws.amazon.com/elasticsearch-service/pricing/">scale up</a>
later.</p>

<p>Once you start a cluster or sign up to a service, you'll get a URL and probably a 
<b>username:password</b> combination. Put those in your <b>worker/secrets/settings.json</b> like so:</p>

<pre>
<code>{
  "index": {
    "url": "https://username:password@your.index.com"
  }
}</code>
</pre>

<p>Installing your own Elasticsearch is pretty easy to start with, although it can 
get complicated to scale up for production. Their docs explains how. Rather than 
us writing more instructions that will get out of date, it's best to go straight to the source:</p>

<p>
<ul>
  <li><a target="_blank" href="https://www.elastic.co/elastic-stack">Elasticsearch</a> docs</li>
  <li><a target="_blank" href="https://opendistro.github.io/for-elasticsearch-docs/docs/install">Elasticsearch Open Distro</a> docs</li>
</ul>
</p>


<h2>Sysadmin</h2>

<p>For long term running on a background server, use <a href="https://pm2.keymetrics.io/docs/usage/quick-start/">PM2</a> instead of just calling node directly.</p>

<pre>
<code>cd API
pm2 start server/dist/server.min.js -i 3 --name paradigm --node-args="--max_old_space_size=3072" --watch</code>
</pre>

<p>The above starts and monitors an instance of the app with 3 "workers", named 
"paradigm", with a max memory of 3072MB and watching to reload on file changes. The "name" can be anything, 
it is just useful to distinguish running apps later. You could start a production 
one called <b>paradigm</b> and a dev one called <b>paradigm_b</b>, for exampmle. Using "watch" 
is useful if you want automatic restarts on code change, but that also may not 
be great on dev if you do want long-running jobs to continue even if underlying 
code changes. That's just a choice, depending on work patterns.</p>

<p>After starting the app with PM2 you can <b>save</b> the state, and PM2 will then 
ensure that the app starts back up in the same state. You can check the status 
of running apps with the <b>status</b> command. You can monitor all action with 
<b>monit</b>. If you make changes to the code and re-run the constructor, you can 
use <b>reload</b> to get PM2 to pick up the changes in the running app (it's 
also possible to start the app with the --watch command, and it will auto reload 
if there are any changes within the folder you started from). You can also check 
what the app is logging using <b>logs</b>.</p>

<pre>
<code>pm2 status
pm2 monit
pm2 reload paradigm_b
pm2 logs paradigm_b</code>
</pre>

<p>Use the <b>htop</b> command line tool to check the overall machine state, CPU 
usage, memory usage, etc. Note that our Elasticsearch configuration reserves 
half the memory for Elasticsearch, but it can also use up the remaning machine 
memory when processing shards in memory.</p>

<p>Elasticsearch is the single point of failure. Check the <b>status</b> of Elasticsearch 
using the command line <b>service</b> manager. You can <b>restart</b> Elasticsearch if it does 
not show as active (this may happen if a very large process causes it to use all 
spare memory on the machine, suffering an OOM error).</p>

<pre>
<code>sudo service elasticsearch status</code>
</pre>

<p><b>BEWARE:</b> If Elasticsearch goes down, the running app will not be able to 
respond to any requests that require interaction with stored records. Also, restarting 
Elasticsearch can take a couple or a few minutes. So only do it when it's necessary, 
for example when it has already crashed. Also, if it crashes, it may dump a memory 
pid file which can be very large - if so, delete it or eventually there will be no 
disk space left. They can often be found in /var/lib/elasticsearch.</p>

<p>There is also a restarter script provided which can be run on a cron job. It 
will check if Elasticsearch is down and if so it will attempt a restart. It also 
checks to see if the PM2 status indicates any unexpected failure, and if so it 
attempts a reload. See restarter.sh in the git repo for more info.</p>

<p>The API app writes logs to a logs index. These can be queried later to review 
activity. The easiest way to do this is via a Kibana instance, which you could 
install alongside Elasticsearch. See the Elasticsearch website for more info.</p>

<p>Once the API is up and running on a background server, it needs to be exposed 
to the wider world. We use <b>nginx</b> for that. There is an example nginx file 
in the git repo. The settings files can also be updated with the <b>bg</b> URL 
for the running background server app, so that Cloudflare workers can pass back 
to them. nginx can also be used to expose Elasticsearch and Kibana. You'll need 
a domain name to route to your background server - that can be controlled via 
Cloudflare or any other DNS provider.</p>

<p><br><br><br><br><br><br><br></p>


</body>

<script>
var toc = '<div class="contentsContainer" style="font-size:0.9em; overflow-y:auto; height:100%;"><ul>';
var counter = 0;

['h2'].forEach(function(t) {
  var elements = document.getElementsByTagName(t);
  for (var i=0; i<elements.length; i++) {
    counter++;
    var el = elements[i];
    var header = el.innerHTML;
    el.innerHTML = '<a name="toc' + counter + '"></a>' + header;
    toc += '<li>';
    var spaces = 0;
    var ms = 2 * (parseInt(el.nodeName.toLowerCase().replace('h','')) - 2);
    while (spaces < ms) {
      toc += '&nbsp;';
      spaces++;
    }
    toc += '<a href="#toc' + counter + '">' + header + '</a></li>';
  }
});
document.getElementsByClassName('contents')[0].innerHTML = toc + '</ul></div>';

['installing', 'requesting'].forEach(function(cls) {
  var elements = document.getElementsByClassName(cls);
  for (var i=0; i<elements.length; i++) {
    var el = elements[i];
    el.addEventListener('click', function(e) {
      e.preventDefault();
      var hs = document.getElementsByClassName(cls.replace('ing', ''));
      for (var h=0; h<hs.length; h++) hs[h].style.display = 'none';
      var ss = document.getElementsByClassName(e.target.getAttribute('href'));
      for (var s=0; s<ss.length; s++)  ss[s].style.display = 'block';
    });
  }
});
</script>

</html>
